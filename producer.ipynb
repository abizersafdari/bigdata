{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if \"HADOOP_CONF_DIR\" in os.environ:\n",
    "   del os.environ[\"HADOOP_CONF_DIR\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"HADOOP_CONF_DIR\" in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web UI: http://10.128.37.127:4040\n",
      "\n",
      "log4j file: /home/jovyan/nfs-home/conf/pyspark-log4j-producer.properties\n",
      "\n",
      "driver log file: /home/jovyan/nfs-home/logs/pyspark-producer.log\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, length, when, col\n",
    "from pyspark.sql.types import BooleanType, IntegerType, LongType, StringType, ArrayType, FloatType, StructType, StructField\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.functions import PandasUDFType\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "\n",
    "# setting constants\n",
    "APP_NAME = \"producer\"\n",
    "NORMALIZED_APP_NAME = APP_NAME.replace('/', '_').replace(':', '_')\n",
    "\n",
    "APPS_TMP_DIR = os.path.join(os.getcwd(), \"tmp\")\n",
    "APPS_CONF_DIR = os.path.join(os.getcwd(), \"conf\")\n",
    "APPS_LOGS_DIR = os.path.join(os.getcwd(), \"logs\")\n",
    "LOG4J_PROP_FILE = os.path.join(APPS_CONF_DIR, \"pyspark-log4j-{}.properties\".format(NORMALIZED_APP_NAME))\n",
    "LOG_FILE = os.path.join(APPS_LOGS_DIR, 'pyspark-{}.log'.format(NORMALIZED_APP_NAME))\n",
    "EXTRA_JAVA_OPTIONS = \"-Dlog4j.configuration=file://{} -Dspark.hadoop.dfs.replication=1 -Dhttps.protocols=TLSv1.0,TLSv1.1,TLSv1.2,TLSv1.3\"\\\n",
    "    .format(LOG4J_PROP_FILE)\n",
    "\n",
    "LOCAL_IP = socket.gethostbyname(socket.gethostname())\n",
    "\n",
    "# preparing configuration files from templates\n",
    "for directory in [APPS_CONF_DIR, APPS_LOGS_DIR, APPS_TMP_DIR]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "env = Environment(loader=FileSystemLoader('/opt'))\n",
    "template = env.get_template(\"pyspark_log4j.properties.template\")\n",
    "template\\\n",
    "    .stream(logfile=LOG_FILE)\\\n",
    "    .dump(LOG4J_PROP_FILE)\n",
    "\n",
    "# run spark\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(APP_NAME)\\\n",
    "    .master(\"k8s://https://10.32.7.103:6443\")\\\n",
    "    .config(\"spark.driver.host\", LOCAL_IP)\\\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\\\n",
    "    .config(\"spark.executor.instances\", \"2\")\\\n",
    "    .config(\"spark.executor.cores\", '3')\\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\")\\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.6\")\\\n",
    "    .config(\"spark.executor.memory\", '3g')\\\n",
    "    .config(\"spark.driver.memory\", \"3g\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"1g\")\\\n",
    "    .config(\"spark.kubernetes.memoryOverheadFactor\", \"0.3\")\\\n",
    "    .config(\"spark.driver.extraJavaOptions\", EXTRA_JAVA_OPTIONS)\\\n",
    "    .config(\"spark.kubernetes.namespace\", \"sabizer-297910\")\\\n",
    "    .config(\"spark.kubernetes.driver.label.appname\", APP_NAME)\\\n",
    "    .config(\"spark.kubernetes.executor.label.appname\", APP_NAME)\\\n",
    "    .config(\"spark.kubernetes.container.image\", \"node03.st:5000/spark-executor:sabizer-297910\")\\\n",
    "    .config(\"spark.local.dir\", \"/tmp/spark\")\\\n",
    "    .config(\"spark.driver.extraClassPath\", \"/home/jovyan/shared-data/my-project-name-jar-with-dependencies.jar\")\\\n",
    "    .config(\"spark.executor.extraClassPath\", \"/home/jovyan/shared-data/my-project-name-jar-with-dependencies.jar\")\\\n",
    "    .config(\"spark.kubernetes.executor.volumes.emptyDir.spark-local-dir-tmp-spark.mount.path\", \"/tmp/spark\")\\\n",
    "    .config(\"spark.kubernetes.executor.volumes.emptyDir.spark-local-dir-tmp-spark.mount.readOnly\", \"false\")\\\n",
    "    .config(\"spark.kubernetes.executor.volumes.hostPath.depdir.mount.path\", \"/home/jovyan/shared-data\")\\\n",
    "    .config(\"spark.kubernetes.executor.volumes.hostPath.depdir.options.path\", \"/nfs/shared\")\\\n",
    "    .config(\"spark.kubernetes.executor.volumes.hostPath.depdir.options.type\", \"Directory\")\\\n",
    "    .config(\"spark.kubernetes.executor.volumes.hostPath.depdir.mount.readOnly\", \"true\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# printing important urls and pathes\n",
    "print(\"Web UI: {}\".format(spark.sparkContext.uiWebUrl))\n",
    "print(\"\\nlog4j file: {}\".format(LOG4J_PROP_FILE))\n",
    "print(\"\\ndriver log file: {}\".format(LOG_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "from kafka import KafkaProducer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+\n",
      "|user_id|                text| timestamp|\n",
      "+-------+--------------------+----------+\n",
      "|  57114|Я всё время себя ...|1552061847|\n",
      "|  57114|Я наверно не тот ...|1552066470|\n",
      "|  57114|Местами дождь, ме...|1552223531|\n",
      "|  57114|Ну отчего все так...|1552250945|\n",
      "|  57114|Друзья, давайте в...|1552309202|\n",
      "+-------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posts_df = spark.read.json(\"/home/jovyan/shared-data/bigdata20/followers_posts_api_final.json\")\\\n",
    "    .select(col(\"owner_id\").alias(\"user_id\"), \"text\", col(\"date\").alias(\"timestamp\"))\\\n",
    "    .where(\"text != ''\")\n",
    "posts_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----+\n",
      "|user_id|sex| age|\n",
      "+-------+---+----+\n",
      "|     34|  F|null|\n",
      "|    102|  F|null|\n",
      "|    175|  M|null|\n",
      "|    243|  F|  34|\n",
      "|    533|  M|  32|\n",
      "+-------+---+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile_df = spark.read.json(\"/home/jovyan/shared-data/bigdata20/followers_info.json\").select(\n",
    "        col(\"id\").alias(\"user_id\"), (\n",
    "            when(col(\"sex\") == lit(1), lit(\"F\"))\n",
    "            .when(col(\"sex\") == lit(2), lit(\"M\"))\n",
    "            .otherwise(lit(None))\n",
    "        ).alias(\"sex\"),\n",
    "        (months_between(\n",
    "            current_date(), \n",
    "            concat_ws(\n",
    "                \"-\", regexp_extract(col(\"bdate\"), r\"(\\d{1,2})\\.(\\d{1,2})\\.(\\d{4})\", 3).cast(\"int\"), \n",
    "                regexp_extract(col(\"bdate\"), r\"(\\d{1,2})\\.(\\d{1,2})\\.(\\d{4})\", 2).cast(\"int\"), \n",
    "                regexp_extract(col(\"bdate\"), r\"(\\d{1,2})\\.(\\d{1,2})\\.(\\d{4})\", 1).cast(\"int\")\n",
    "            ).cast(\"date\")\n",
    "        ) / lit(12)).cast(\"int\").alias(\"age\")\n",
    "    )\n",
    "profile_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      "\n",
      "+-------+---+----+--------------------+----------+\n",
      "|user_id|sex| age|                text| timestamp|\n",
      "+-------+---+----+--------------------+----------+\n",
      "|  39499|  M|  14|        #ЧайнаяЛента|1554622080|\n",
      "|  39499|  M|  14|Побывали в [club2...|1554742564|\n",
      "|  68686|  M|null|Полезный курс для...|1550587946|\n",
      "|  60086|  M|  34|С днем рождения! ...|1556793944|\n",
      "|  71307|  M|null|Женька, мой герой...|1552734777|\n",
      "+-------+---+----+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_post_df = posts_df.join(broadcast(profile_df), [\"user_id\"])\\\n",
    "    .select(\"user_id\", \"sex\", \"age\", \"text\", \"timestamp\")\n",
    "user_post_df.printSchema()\n",
    "user_post_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_post_cnt = user_post_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 112307/163196 [3:12:27<1:26:13,  9.84it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 163196/163196 [4:39:54<00:00,  9.72it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================ \n",
      "Producer finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=\"kafka-svc:9092\", value_serializer=str.encode)\n",
    "topic_name = \"vk_post_topic\"\n",
    "\n",
    "for row in tqdm(user_post_df.orderBy(\"timestamp\").rdd.toLocalIterator(), total=user_post_cnt):\n",
    "    value = json.dumps(row.asDict(), ensure_ascii=False)\n",
    "    producer.send(topic_name, json.dumps(row.asDict(), ensure_ascii=False))\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print(\"=\" * 80, \"\\nProducer finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
